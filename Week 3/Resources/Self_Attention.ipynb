{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2984db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f3e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Life is short, eat dessert first\"\n",
    "dictionary = {s:i for i,s in enumerate(sorted(sentence.replace(',','').split()))}\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2c44f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 5, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "sentence_int = torch.tensor([dictionary[s] for s in sentence.replace(',','').split()])\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e4d163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
      "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
      "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n",
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(6,16) # each word will be an embedding of dimension 16 and there are 6 words\n",
    "embedded_sentence = embed(sentence_int).detach()\n",
    "print(embedded_sentence)\n",
    "print(embedded_sentence.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e801ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "d_q,d_k,d_v = 24,24,28 # Shapes of Q = d_q*d , K = d_k*d , V =d_v*d   \n",
    "# Since we want Q.K^T => d_q = d_k\n",
    "W_query = torch.nn.Parameter(torch.rand(d_q,d))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_k,d))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_v,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add8d1a",
   "metadata": {},
   "source": [
    "##### Computing Attention vector for second input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdc453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24])\n",
      "torch.Size([24])\n",
      "torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = W_query.matmul(x_2)\n",
    "key_2 = W_key.matmul(x_2)\n",
    "value_2 = W_value.matmul(x_2)\n",
    "\n",
    "print(query_2.shape)\n",
    "print(key_2.shape)\n",
    "print(value_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3615647",
   "metadata": {},
   "source": [
    "##### Computing Key vector and value vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51ade15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 24])\n",
      "values.shape: torch.Size([6, 28])\n"
     ]
    }
   ],
   "source": [
    "keys = W_key.matmul(embedded_sentence.T).T\n",
    "values = W_value.matmul(embedded_sentence.T).T\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c922b2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1466, grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "omega_24 = query_2.dot(keys[4]) # unnormalized weight for query and the 5th input element i.e. 2 and 4 index\n",
    "print(omega_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60cdb32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.5808, -7.6597,  3.2558,  1.0395, 11.1466, -0.4800],\n",
      "       grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "omega_2 = query_2.matmul(keys.T)\n",
    "print(omega_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9041f4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2912, 0.0106, 0.0982, 0.0625, 0.4917, 0.0458],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "attention_weights_2 = F.softmax(omega_2/ d_k**0.5,dim=0)\n",
    "print(attention_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbd90199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28])\n",
      "tensor([-1.5993,  0.0156,  1.2670,  0.0032, -0.6460, -1.1407, -0.4908, -1.4632,\n",
      "         0.4747,  1.1926,  0.4506, -0.7110,  0.0602,  0.7125, -0.1628, -2.0184,\n",
      "         0.3838, -2.1188, -0.8136, -1.5694,  0.7934, -0.2911, -1.3640, -0.2366,\n",
      "        -0.9564, -0.5265,  0.0624,  1.7084], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "context_vector_2 = attention_weights_2.matmul(values)\n",
    "\n",
    "print(context_vector_2.shape)\n",
    "print(context_vector_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c08e42",
   "metadata": {},
   "source": [
    "### Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70890525",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 3\n",
    "multihead_W_query = torch.nn.Parameter(torch.rand(h,d_q,d))\n",
    "multihead_W_key = torch.nn.Parameter(torch.rand(h, d_k, d))\n",
    "multihead_W_value = torch.nn.Parameter(torch.rand(h, d_v, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e540629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24])\n"
     ]
    }
   ],
   "source": [
    "multihead_query_2 = multihead_W_query.matmul(x_2)\n",
    "print(multihead_query_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0713e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_key_2 = multihead_W_key.matmul(x_2)\n",
    "multihead_value_2 = multihead_W_value.matmul(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d7aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 6])\n"
     ]
    }
   ],
   "source": [
    "stacked_inputs = embedded_sentence.T.repeat(3, 1, 1)\n",
    "print(stacked_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21fc1ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multihead_keys.shape: torch.Size([3, 24, 6])\n",
      "multihead_values.shape: torch.Size([3, 28, 6])\n"
     ]
    }
   ],
   "source": [
    "multihead_keys = torch.bmm(multihead_W_key, stacked_inputs) # bmm is batch matrix multiplication\n",
    "multihead_values = torch.bmm(multihead_W_value, stacked_inputs)\n",
    "print(\"multihead_keys.shape:\", multihead_keys.shape)\n",
    "print(\"multihead_values.shape:\", multihead_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda1582",
   "metadata": {},
   "source": [
    "To make the values and keys more intuitive to interpret, we will swap the second and third dimensions, resulting in tensors with the same dimensional structure as the original input sequence, embedded_sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb3df123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multihead_keys.shape: torch.Size([3, 6, 24])\n",
      "multihead_values.shape: torch.Size([3, 6, 28])\n"
     ]
    }
   ],
   "source": [
    "multihead_keys = multihead_keys.permute(0, 2, 1)\n",
    "multihead_values = multihead_values.permute(0, 2, 1)\n",
    "print(\"multihead_keys.shape:\", multihead_keys.shape)\n",
    "print(\"multihead_values.shape:\", multihead_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b843261",
   "metadata": {},
   "source": [
    "##### Cross Attention\n",
    "Note that the queries usually come from the decoder, and the keys and values usually come from the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa80ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([8, 24])\n",
      "values.shape: torch.Size([8, 28])\n"
     ]
    }
   ],
   "source": [
    "# Decoder part\n",
    "embedded_sentence_2 = torch.rand(8,16) # dimension of embedding should match number of tokens may be different\n",
    "\n",
    "keys = W_key.matmul(embedded_sentence_2.T).T\n",
    "values = W_value.matmul(embedded_sentence_2.T).T\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
