{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e266c2",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d58d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'star': 1, 'is': 2, 'moon': 3, 'and': 4, 'celestial': 5, 'the': 6, 'bodies': 7, 'satellite': 8, 'are': 9, 'sun': 10}\n",
      "Vectorization of the Corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       " [1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'the sun is a star',\n",
    "    'the moon is a satellite',\n",
    "    'the sun and moon are celestial bodies'\n",
    "]\n",
    "\n",
    "# Creating the vocabulary\n",
    "vocabulary = set()\n",
    "\n",
    "for documents in corpus:\n",
    "    words = documents.lower().split()\n",
    "    for word in words:\n",
    "        vocabulary.add(word)\n",
    "\n",
    "vocabulary = list(vocabulary)\n",
    "word_to_index = {word:i for i,word in enumerate(vocabulary)}\n",
    "\n",
    "def Count_vectorizer(corpus,vocabulary,word_to_index):\n",
    "    vectorization = list()\n",
    "    for sentence in corpus:\n",
    "        vector = [0] * len(vocabulary)\n",
    "        words = sentence.lower().split()\n",
    "        for word in words:\n",
    "            vector[word_to_index[word]] += 1\n",
    "        vectorization.append(vector)\n",
    "    \n",
    "    return vectorization\n",
    "        \n",
    "print(word_to_index)\n",
    "print(\"Vectorization of the Corpus\")\n",
    "Count_vectorizer(corpus,vocabulary,word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db266c",
   "metadata": {},
   "source": [
    "#### Count Vectorizer using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc4a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'are' 'bodies' 'celestial' 'is' 'moon' 'satellite' 'star' 'sun'\n",
      " 'the']\n",
      "[[0 0 0 0 1 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 0 0 1]\n",
      " [1 1 1 1 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "Vectorizer = CountVectorizer()\n",
    "X = Vectorizer.fit_transform(corpus)\n",
    "print(Vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09cb7c",
   "metadata": {},
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492f2125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERM FREQUENCY\n",
      "\n",
      "Document 1 :\n",
      "the : 1\n",
      "sun : 1\n",
      "is : 1\n",
      "a : 1\n",
      "star : 1\n",
      "\n",
      "\n",
      "Document 2 :\n",
      "the : 1\n",
      "moon : 1\n",
      "is : 1\n",
      "a : 1\n",
      "satellite : 1\n",
      "\n",
      "\n",
      "Document 3 :\n",
      "the : 1\n",
      "sun : 1\n",
      "and : 1\n",
      "moon : 1\n",
      "are : 1\n",
      "celestial : 1\n",
      "bodies : 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TERM FREQUENCY\\n\")\n",
    "def Term_Frequency(word,sentence):\n",
    "    words = sentence.lower().split()\n",
    "    freq_dict = {}\n",
    "    for word in words:\n",
    "        freq_dict[word] = freq_dict.get(word,0) + 1\n",
    "    return freq_dict[word]\n",
    "\n",
    "for doc_index,document in enumerate(corpus):\n",
    "    print(f\"Document {doc_index + 1} :\")\n",
    "    words = document.lower().split()\n",
    "    for word in words:\n",
    "        print(f\"{word} : {Term_Frequency(word,document)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd370b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Document Frequency\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'the': 0.0,\n",
       " 'sun': 0.3521825181113625,\n",
       " 'is': 0.3521825181113625,\n",
       " 'a': 0.3521825181113625,\n",
       " 'star': 0.47712125471966244,\n",
       " 'moon': 0.3521825181113625,\n",
       " 'satellite': 0.47712125471966244,\n",
       " 'and': 0.47712125471966244,\n",
       " 'are': 0.47712125471966244,\n",
       " 'celestial': 0.47712125471966244,\n",
       " 'bodies': 0.47712125471966244}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def Inverse_Doc_Frequecy(word,corpus):\n",
    "    count = 0\n",
    "    total = len(corpus)\n",
    "    for document in corpus:\n",
    "        words = document.lower().split()\n",
    "        if word in words:\n",
    "            count += 1\n",
    "    return math.log10((total)/(count))\n",
    "\n",
    "IDF = {}\n",
    "for document in corpus:\n",
    "    words = document.lower().split()\n",
    "    for word in words:\n",
    "        IDF[word] = IDF.get(word,0) + Inverse_Doc_Frequecy(word,corpus)\n",
    "print(\"Inverse Document Frequency\")\n",
    "IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4fa2a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF SCORE\n",
      "Document 1 :\n",
      "the : 0.0\n",
      "sun : 0.3521825181113625\n",
      "is : 0.3521825181113625\n",
      "a : 0.3521825181113625\n",
      "star : 0.47712125471966244\n",
      "\n",
      "\n",
      "Document 2 :\n",
      "the : 0.0\n",
      "moon : 0.3521825181113625\n",
      "is : 0.3521825181113625\n",
      "a : 0.3521825181113625\n",
      "satellite : 0.47712125471966244\n",
      "\n",
      "\n",
      "Document 3 :\n",
      "the : 0.0\n",
      "sun : 0.3521825181113625\n",
      "and : 0.47712125471966244\n",
      "moon : 0.3521825181113625\n",
      "are : 0.47712125471966244\n",
      "celestial : 0.47712125471966244\n",
      "bodies : 0.47712125471966244\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF SCORE\")\n",
    "for doc_index,document in enumerate(corpus):\n",
    "    print(f\"Document {doc_index + 1} :\")\n",
    "    words = document.lower().split()\n",
    "    for word in words:\n",
    "        print(f\"{word} : {Term_Frequency(word,document)*IDF[word]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f00547",
   "metadata": {},
   "source": [
    "#### TF-IDF using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559f7fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "  the: 0.3363\n",
      "  sun: 0.4331\n",
      "  is: 0.4331\n",
      "  a: 0.4331\n",
      "  star: 0.5694\n",
      "\n",
      "Document 2:\n",
      "  the: 0.3363\n",
      "  is: 0.4331\n",
      "  a: 0.4331\n",
      "  moon: 0.4331\n",
      "  satellite: 0.5694\n",
      "\n",
      "Document 3:\n",
      "  the: 0.2517\n",
      "  sun: 0.3241\n",
      "  moon: 0.3241\n",
      "  and: 0.4262\n",
      "  are: 0.4262\n",
      "  celestial: 0.4262\n",
      "  bodies: 0.4262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'(?u)\\b\\w+\\b') # To include 1 char tokens\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_values = {}\n",
    "\n",
    "for doc_index in range(len(corpus)):\n",
    "    row = tfidf_matrix[doc_index]\n",
    "    indices = row.indices\n",
    "    data = row.data\n",
    "    tfidf_values[doc_index] = {feature_names[i]: round(score,4) for i,score in zip(indices,data)}\n",
    "\n",
    "for doc_index, values in tfidf_values.items():\n",
    "    print(f\"Document {doc_index+1}:\")\n",
    "    for word, tfidf_value in values.items():\n",
    "        print(f\"  {word}: {tfidf_value}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
